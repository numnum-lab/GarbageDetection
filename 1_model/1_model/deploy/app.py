import cv2
import streamlit as st
from ultralytics import YOLO
import tempfile
from PIL import Image
import numpy as np
import sys
from pathlib import Path
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, ClientSettings
import av
import os
import torch
from ultralytics.nn.tasks import DetectionModel
from functools import partial
from huggingface_hub import hf_hub_download
if "is_webcam_active" not in st.session_state:
    st.session_state.is_webcam_active = False

if "is_detecting" not in st.session_state:
    st.session_state.is_detecting = False

if "detected_classes" not in st.session_state:
    st.session_state.detected_classes = []

if "confidence_threshold" not in st.session_state:
    st.session_state.confidence_threshold = 0.2
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded",
    page_title="Object Detection",
)

# ‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ç‡∏≠‡∏á YOLO ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏∞
yolo_classes = [
    "battery", "biological", "cardboard", "clothes", "glass", 
    "metal", "paper", "plastic", "shoes", "trash"
]

disposal_messages = {
    "battery": "‚ö° **Battery detected!** Dispose in the **HAZARDOUS** bin.",
    "biological": "üçÉ **Biological waste detected!** Dispose in the **ORGANIC** bin.",
    "cardboard": "üì¶ **Cardboard detected!** Flatten and dispose in the **RECYCLING** bin.",
    "clothes": "üëï **Clothes detected!** Consider donating, or dispose in the **GENERAL** bin.",
    "glass": "üç∂ **Glass detected!** Dispose in the **RECYCLING** bin.",
    "metal": "üî© **Metal detected!** Dispose in the **RECYCLING** bin.",
    "paper": "üìÑ **Paper detected!** Dispose in the **RECYCLING** bin.",
    "plastic": "‚ôªÔ∏è **Plastic detected!** Dispose in the **RECYCLING** bin.",
    "shoes": "üëü **Shoes detected!** Consider donating, or dispose in the **GENERAL** bin.",
    "trash": "üóëÔ∏è **General trash detected!** Dispose in the **GENERAL** bin.",
}

# ---
### **‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç)**

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Hugging Face Hub ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ cache
@st.cache_resource
def load_yolo_model():
    try:
        st.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Hugging Face...")
        
        # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠ repo_id ‡πÅ‡∏•‡∏∞ filename ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        repo_id = "Numgfsdf/garbage-detection-model"
        filename = "my_model.pt"

        # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Hugging Face
        model_path = hf_hub_download(repo_id=repo_id, filename=filename)
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
        with torch.serialization.safe_globals([DetectionModel]):
            model = YOLO(model_path)
            
        st.success(f"‡πÇ‡∏´‡∏•‡∏î YOLO Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏à‡∏≤‡∏Å {model_path}!")
        return model
        
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏´‡∏•‡∏î YOLO model: {e}")
        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠ repo_id ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Hugging Face")
        return None

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
if "yolo_model" not in st.session_state:
    st.session_state.yolo_model = load_yolo_model()

# ---
### **‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)**

# ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°
class YOLOProcessor(VideoProcessorBase):
    def __init__(self, yolo_model, conf_threshold):
        self.model = yolo_model
        self.conf_threshold = conf_threshold
        
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        
        results = self.model.predict(source=img, conf=self.conf_threshold)
        detections = results[0]
        
        boxes = (detections.boxes.xyxy.cpu().numpy() if len(detections) > 0 else [])
        confs = (detections.boxes.conf.cpu().numpy() if len(detections) > 0 else [])
        class_ids = (detections.boxes.cls.cpu().numpy().astype(int) if len(detections) > 0 else [])
        
        detected_classes = [yolo_classes[int(cls_id)] for cls_id in class_ids]
        
        if detected_classes:
            st.session_state['detected_classes'] = detected_classes
        else:
            st.session_state['detected_classes'] = []
            
        for i, box in enumerate(boxes):
            x1, y1, x2, y2 = map(int, box)
            label = f"{yolo_classes[class_ids[i]]}: {confs[i]:.2f}"
            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)
            cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ---
### **‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)**

def display_detection_messages(detected_classes):
    if detected_classes:
        st.subheader("üéØ Detection Results:")
        unique_classes = list(set(detected_classes))
        
        if len(unique_classes) <= 2:
            cols = st.columns(len(unique_classes))
        else:
            cols = st.columns(2)
        
        for i, class_name in enumerate(unique_classes):
            col_index = i if len(unique_classes) <= 2 else i % 2
            with cols[col_index]:
                if class_name == "battery":
                    st.error(f"üü• {disposal_messages[class_name]}")
                elif class_name == "biological":
                    st.success(f"üü¢ {disposal_messages[class_name]}")
                elif class_name in ["cardboard", "glass", "metal", "paper", "plastic"]:
                    st.warning(f"üü° {disposal_messages[class_name]}")
                elif class_name in ["clothes", "shoes"]:
                    st.info(f"üü¶ {disposal_messages[class_name]}")
                else:
                    st.error(f"‚¨õ {disposal_messages[class_name]}")

def image_detection(uploaded_file, conf_threshold, selected_classes):
    if not st.session_state.yolo_model:
        st.error("YOLO model is not loaded. Cannot perform image detection.")
        return

    image = Image.open(uploaded_file)
    image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    
    results = st.session_state.yolo_model.predict(source=image_cv, conf=conf_threshold)
    detections = results[0]
    
    boxes = detections.boxes.xyxy.cpu().numpy()
    confs = detections.boxes.conf.cpu().numpy()
    class_ids = detections.boxes.cls.cpu().numpy().astype(int)
    
    detected_classes = []
    if selected_classes:
        filtered = [
            (box, conf, class_id)
            for box, conf, class_id in zip(boxes, confs, class_ids)
            if yolo_classes[class_id] in selected_classes
        ]
        if filtered:
            boxes, confs, class_ids = zip(*filtered)
            detected_classes = [yolo_classes[class_id] for class_id in class_ids]
        else:
            boxes, confs, class_ids = [], [], []
    else:
        detected_classes = [yolo_classes[class_id] for class_id in class_ids]
    
    for i, box in enumerate(boxes):
        x1, y1, x2, y2 = map(int, box)
        label = f"{yolo_classes[class_ids[i]]}: {confs[i]:.2f}"
        cv2.rectangle(image_cv, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)
        cv2.putText(image_cv, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.image(image_cv, channels="BGR")
    with col2:
        display_detection_messages(detected_classes)

# ---
### **Main App Logic**

# Sidebar controls
with st.sidebar:
    st.title("Object Detection Settings ‚öôÔ∏è")
    confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.2)
    st.session_state.confidence_threshold = confidence_threshold
    
    selected_classes = st.multiselect("Select classes for object detection", yolo_classes)
    
    uploaded_file = st.file_uploader(
        "Upload an image or video üì§",
        type=["mp4", "mov", "avi", "m4v", "jpg", "png", "jpeg"],
    )
    
    if st.button("Use Webcam üì∑" if not st.session_state.is_webcam_active else "Stop Webcam üõë"):
        st.session_state.is_webcam_active = not st.session_state.is_webcam_active
        if st.session_state.is_webcam_active:
            st.session_state.is_detecting = True
        else:
            st.session_state.is_detecting = False
    
    detect_button = st.button(
        ("Start Detection ‚ñ∂Ô∏è" if not st.session_state.is_detecting else "Stop Detection üõë"),
        disabled=(not uploaded_file and not st.session_state.is_webcam_active),
    )
    
    if detect_button:
        st.session_state.is_detecting = not st.session_state.is_detecting
    
    # Disposal Guide
    st.markdown("---")
    st.subheader("üìã Disposal Guide")
    with st.expander("View all disposal instructions"):
        st.markdown("### üü• **Hazardous Bin**")
        st.error("‚ö° **Battery:** Dispose in the **HAZARDOUS** bin.")
        st.markdown("### üü¢ **Organic Bin**")
        st.success("üçÉ **Biological:** Dispose in the **ORGANIC** bin.")
        st.markdown("### üü° **Recyclables**")
        st.warning("üì¶ **Cardboard:** Flatten and dispose in the **RECYCLING** bin.")
        st.warning("üç∂ **Glass:** Dispose in the **RECYCLING** bin.")
        st.warning("üî© **Metal:** Dispose in the **RECYCLING** bin.")
        st.warning("üìÑ **Paper:** Dispose in the **RECYCLING** bin.")
        st.warning("‚ôªÔ∏è **Plastic:** Dispose in the **RECYCLING** bin.")
        st.markdown("### üü¶ **Donate**")
        st.info("üëï **Clothes:** Consider **Donating** or dispose in the **GENERAL** bin.")
        st.info("üëü **Shoes:** Consider **Donating** or dispose in the **GENERAL** bin.")
        st.markdown("### ‚¨õ **General Waste**")
        st.error("üóëÔ∏è **Trash:** Dispose in the **GENERAL** bin.")

# Main app logic
if st.session_state.is_detecting:
    if st.session_state.is_webcam_active:
        st.info("Detecting objects using webcam...")
        if "yolo_model" in st.session_state and st.session_state.yolo_model:
            # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ functools.partial ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ
            processor_factory = partial(
                YOLOProcessor,
                yolo_model=st.session_state.yolo_model,
                conf_threshold=st.session_state.confidence_threshold
            )
            
            webrtc_streamer(
                key="yolo-stream",
                video_processor_factory=processor_factory,
                rtc_configuration=ClientSettings(
                    rtc_offer_min_port=10000,
                    rtc_offer_max_port=10200,
                ),
            )
            if "detected_classes" in st.session_state:
                display_detection_messages(st.session_state.detected_classes)
        else:
            st.error("YOLO model is not loaded. Please check the logs for errors.")
            
    elif uploaded_file:
        file_extension = uploaded_file.name.split(".")[-1].lower()
        if file_extension in ["jpg", "jpeg", "png"]:
            st.info("Detecting objects in image...")
            image_detection(uploaded_file, confidence_threshold, selected_classes)
        else:
            st.warning("Video processing not implemented in this version")
else:
    st.title("Smart Garbage Detection & Sorting Assistant")
    st.info("Upload an image or video, or start the webcam for object detection.")
    
    col1, col2 = st.columns(2)
    with col1:
        st.write("""
        ### üóÇÔ∏è Garbage Detection Using YOLO
        This is a group project by **Num Chakhatanon** and **Dawis Meedech** to help people sort garbage more easily.
        
        **Features:**
        - Real-time object detection via webcam
        - Image analysis
        - Smart disposal recommendations
        - Multiple waste categories supported
        """)
    
    with col2:
        st.write("""
        ### üìñ How to Use:
        1. **Upload** an image or use your **webcam**
        2. **Adjust** confidence threshold as needed
        3. **Select** specific classes to detect (optional)
        4. **Start detection** and follow the disposal instructions
        
        The system will automatically provide disposal guidance for detected items!
        """)