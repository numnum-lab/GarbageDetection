import cv2
import streamlit as st
from ultralytics import YOLO
import tempfile
from PIL import Image
import numpy as np
import sys
from pathlib import Path
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, ClientSettings
import av
import os
import torch
from ultralytics.nn.tasks import DetectionModel 

# Set page config first
st.set_page_config(
Â  Â  page_icon="ğŸ”",
Â  Â  layout="wide",
Â  Â  initial_sidebar_state="expanded",
Â  Â  page_title="Object Detection",
)

# Debug: Show current working directory and file structure
if "yolo_model" not in st.session_state:
Â  Â  try:
Â  Â  Â  Â  # Get the directory where the script is located
Â  Â  Â  Â  script_dir = Path(__file__).resolve().parent
Â  Â  Â  Â  model_path = script_dir / "my_model.pt"

Â  Â  Â  Â  # Add the trusted class to PyTorch's allowed globals
Â  Â  Â  Â  with torch.serialization.safe_globals([DetectionModel]):
Â  Â  Â  Â  Â  Â  st.session_state.yolo_model = YOLO(str(model_path))
Â  Â  Â  Â  
Â  Â  Â  Â  st.success(f"YOLO Model loaded successfully!")
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error loading YOLO model: {e}")
Â  Â  Â  Â  st.stop()

# Set up the correct path for imports
current_dir = Path(__file__).resolve().parent
sys.path.append(str(current_dir.parent.parent))

# YOLO classes and messages
yolo_classes = [
Â  Â  "battery", "biological", "cardboard", "clothes", "glass", 
Â  Â  "metal", "paper", "plastic", "shoes", "trash"
]

disposal_messages = {
Â  Â  "battery": "âš¡ **Battery detected!** Dispose in the **HAZARDOUS** bin.",
Â  Â  "biological": "ğŸƒ **Biological waste detected!** Dispose in the **ORGANIC** bin.",
Â  Â  "cardboard": "ğŸ“¦ **Cardboard detected!** Flatten and dispose in the **RECYCLING** bin.",
Â  Â  "clothes": "ğŸ‘• **Clothes detected!** Consider donating, or dispose in the **GENERAL** bin.",
Â  Â  "glass": "ğŸ¶ **Glass detected!** Dispose in the **RECYCLING** bin.",
Â  Â  "metal": "ğŸ”© **Metal detected!** Dispose in the **RECYCLING** bin.",
Â  Â  "paper": "ğŸ“„ **Paper detected!** Dispose in the **RECYCLING** bin.",
Â  Â  "plastic": "â™»ï¸ **Plastic detected!** Dispose in the **RECYCLING** bin.",
Â  Â  "shoes": "ğŸ‘Ÿ **Shoes detected!** Consider donating, or dispose in the **GENERAL** bin.",
Â  Â  "trash": "ğŸ—‘ï¸ **General trash detected!** Dispose in the **GENERAL** bin.",
}

# Initialize session state
if "is_detecting" not in st.session_state:
Â  Â  st.session_state.is_detecting = False
if "is_webcam_active" not in st.session_state:
Â  Â  st.session_state.is_webcam_active = False
if "confidence_threshold" not in st.session_state:
Â  Â  st.session_state.confidence_threshold = 0.2

# Load YOLO model using the correct path
if "yolo_model" not in st.session_state:
Â  Â  try:
Â  Â  Â  Â  # Get the directory where the script is located
Â  Â  Â  Â  script_dir = Path(__file__).resolve().parent
Â  Â  Â  Â  model_path = script_dir / "my_model.pt"
Â  Â  Â  Â  
Â  Â  Â  Â  st.info(f"Trying to load model from: {model_path}")
Â  Â  Â  Â  st.session_state.yolo_model = YOLO(str(model_path))
Â  Â  Â  Â  st.success(f"YOLO Model loaded successfully from: {model_path}")
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error loading YOLO model: {e}")
Â  Â  Â  Â  st.error(f"Attempted path: {script_dir / 'my_model.pt'}")
Â  Â  Â  Â  st.stop()

def display_detection_messages(detected_classes):
Â  Â  """Display disposal messages for detected objects with color coding"""
Â  Â  if detected_classes:
Â  Â  Â  Â  st.subheader("ğŸ¯ Detection Results:")
Â  Â  Â  Â  unique_classes = list(set(detected_classes))
Â  Â  Â  Â  
Â  Â  Â  Â  if len(unique_classes) <= 2:
Â  Â  Â  Â  Â  Â  cols = st.columns(len(unique_classes))
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  cols = st.columns(2)
Â  Â  Â  Â  
Â  Â  Â  Â  for i, class_name in enumerate(unique_classes):
Â  Â  Â  Â  Â  Â  col_index = i if len(unique_classes) <= 2 else i % 2
Â  Â  Â  Â  Â  Â  with cols[col_index]:
Â  Â  Â  Â  Â  Â  Â  Â  if class_name == "battery":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"ğŸŸ¥ {disposal_messages[class_name]}")
Â  Â  Â  Â  Â  Â  Â  Â  elif class_name == "biological":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"ğŸŸ¢ {disposal_messages[class_name]}")
Â  Â  Â  Â  Â  Â  Â  Â  elif class_name in ["cardboard", "glass", "metal", "paper", "plastic"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"ğŸŸ¡ {disposal_messages[class_name]}")
Â  Â  Â  Â  Â  Â  Â  Â  elif class_name in ["clothes", "shoes"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"ğŸŸ¦ {disposal_messages[class_name]}")
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"â¬› {disposal_messages[class_name]}")

class YOLOProcessor(VideoProcessorBase):
Â  Â  def __init__(self, yolo_model, conf_threshold):
Â  Â  Â  Â  self.model = yolo_model
Â  Â  Â  Â  self.conf_threshold = conf_threshold
Â  Â  Â  Â  
Â  Â  def recv(self, frame):
Â  Â  Â  Â  img = frame.to_ndarray(format="bgr24")
Â  Â  Â  Â  
Â  Â  Â  Â  results = self.model.predict(source=img, conf=self.conf_threshold)
Â  Â  Â  Â  detections = results[0]
Â  Â  Â  Â  
Â  Â  Â  Â  boxes = (detections.boxes.xyxy.cpu().numpy() if len(detections) > 0 else [])
Â  Â  Â  Â  confs = (detections.boxes.conf.cpu().numpy() if len(detections) > 0 else [])
Â  Â  Â  Â  class_ids = (detections.boxes.cls.cpu().numpy().astype(int) if len(detections) > 0 else [])
Â  Â  Â  Â  
Â  Â  Â  Â  detected_classes = [yolo_classes[int(cls_id)] for cls_id in class_ids]
Â  Â  Â  Â  
Â  Â  Â  Â # âœ… à¹à¸à¹‰à¹„à¸‚: à¸­à¸±à¸›à¹€à¸”à¸• st.session_state à¹à¸—à¸™à¸à¸²à¸£ return
Â  Â  Â  Â  if detected_classes:
Â  Â  Â  Â  Â  Â  st.session_state['detected_classes'] = detected_classes
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.session_state['detected_classes'] = []
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  # Draw bounding boxes and labels
Â  Â  Â  Â  for i, box in enumerate(boxes):
Â  Â  Â  Â  Â  Â  x1, y1, x2, y2 = map(int, box)
Â  Â  Â  Â  Â  Â  label = f"{yolo_classes[class_ids[i]]}: {confs[i]:.2f}"
Â  Â  Â  Â  Â  Â  cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)
Â  Â  Â  Â  Â  Â  cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  # âœ… à¹à¸à¹‰à¹„à¸‚: return à¹à¸„à¹ˆ VideoFrame
Â  Â  Â  Â  return av.VideoFrame.from_ndarray(img, format="bgr24")


def image_detection(uploaded_file, conf_threshold, selected_classes):
Â  Â  """Process uploaded image"""
Â  Â  image = Image.open(uploaded_file)
Â  Â  image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
Â  Â  
Â  Â  results = st.session_state.yolo_model.predict(source=image_cv, conf=conf_threshold)
Â  Â  detections = results[0]
Â  Â  
Â  Â  boxes = detections.boxes.xyxy.cpu().numpy()
Â  Â  confs = detections.boxes.conf.cpu().numpy()
Â  Â  class_ids = detections.boxes.cls.cpu().numpy().astype(int)
Â  Â  
Â  Â  detected_classes = []
Â  Â  if selected_classes:
Â  Â  Â  Â  filtered = [
Â  Â  Â  Â  Â  Â  (box, conf, class_id)
Â  Â  Â  Â  Â  Â  for box, conf, class_id in zip(boxes, confs, class_ids)
Â  Â  Â  Â  Â  Â  if yolo_classes[class_id] in selected_classes
Â  Â  Â  Â  ]
Â  Â  Â  Â  if filtered:
Â  Â  Â  Â  Â  Â  boxes, confs, class_ids = zip(*filtered)
Â  Â  Â  Â  Â  Â  detected_classes = [yolo_classes[class_id] for class_id in class_ids]
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  boxes, confs, class_ids = [], [], []
Â  Â  else:
Â  Â  Â  Â  detected_classes = [yolo_classes[class_id] for class_id in class_ids]
Â  Â  
Â  Â  # Draw bounding boxes
Â  Â  for i, box in enumerate(boxes):
Â  Â  Â  Â  x1, y1, x2, y2 = map(int, box)
Â  Â  Â  Â  label = f"{yolo_classes[class_ids[i]]}: {confs[i]:.2f}"
Â  Â  Â  Â  cv2.rectangle(image_cv, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)
Â  Â  Â  Â  cv2.putText(image_cv, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
Â  Â  
Â  Â  col1, col2 = st.columns([2, 1])
Â  Â  with col1:
Â  Â  Â  Â  st.image(image_cv, channels="BGR")
Â  Â  with col2:
Â  Â  Â  Â  display_detection_messages(detected_classes)

# Sidebar controls
with st.sidebar:
Â  Â  st.title("Object Detection Settings âš™ï¸")
Â  Â  confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.2)
Â  Â  st.session_state.confidence_threshold = confidence_threshold
Â  Â  
Â  Â  selected_classes = st.multiselect("Select classes for object detection", yolo_classes)
Â  Â  
Â  Â  uploaded_file = st.file_uploader(
Â  Â  Â  Â  "Upload an image or video ğŸ“¤",
Â  Â  Â  Â  type=["mp4", "mov", "avi", "m4v", "jpg", "png", "jpeg"],
Â  Â  )
Â  Â  
Â  Â  if st.button("Use Webcam ğŸ“·" if not st.session_state.is_webcam_active else "Stop Webcam ğŸ›‘"):
Â  Â  Â  Â  st.session_state.is_webcam_active = not st.session_state.is_webcam_active
Â  Â  Â  Â  if st.session_state.is_webcam_active:
Â  Â  Â  Â  Â  Â  st.session_state.is_detecting = True
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.session_state.is_detecting = False
Â  Â  
Â  Â  detect_button = st.button(
Â  Â  Â  Â  ("Start Detection â–¶ï¸" if not st.session_state.is_detecting else "Stop Detection ğŸ›‘"),
Â  Â  Â  Â  disabled=(not uploaded_file and not st.session_state.is_webcam_active),
Â  Â  )
Â  Â  
Â  Â  if detect_button:
Â  Â  Â  Â  st.session_state.is_detecting = not st.session_state.is_detecting
Â  Â  
Â  Â  # Disposal Guide
Â  Â  st.markdown("---")
Â  Â  st.subheader("ğŸ“‹ Disposal Guide")
Â  Â  with st.expander("View all disposal instructions"):
Â  Â  Â  Â  st.markdown("### ğŸŸ¥ **Hazardous Bin**")
Â  Â  Â  Â  st.error("âš¡ **Battery:** Dispose in the **HAZARDOUS** bin.")
Â  Â  Â  Â  
Â  Â  Â  Â  st.markdown("### ğŸŸ¢ **Organic Bin**")
Â  Â  Â  Â  st.success("ğŸƒ **Biological:** Dispose in the **ORGANIC** bin.")
Â  Â  Â  Â  
Â  Â  Â  Â  st.markdown("### ğŸŸ¡ **Recyclables**")
Â  Â  Â  Â  st.warning("ğŸ“¦ **Cardboard:** Flatten and dispose in the **RECYCLING** bin.")
Â  Â  Â  Â  st.warning("ğŸ¶ **Glass:** Dispose in the **RECYCLING** bin.")
Â  Â  Â  Â  st.warning("ğŸ”© **Metal:** Dispose in the **RECYCLING** bin.")
Â  Â  Â  Â  st.warning("ğŸ“„ **Paper:** Dispose in the **RECYCLING** bin.")
Â  Â  Â  Â  st.warning("â™»ï¸ **Plastic:** Dispose in the **RECYCLING** bin.")
Â  Â  Â  Â  
Â  Â  Â  Â  st.markdown("### ğŸŸ¦ **Donate**")
Â  Â  Â  Â  st.info("ğŸ‘• **Clothes:** Consider **Donating** or dispose in the **GENERAL** bin.")
Â  Â  Â  Â  st.info("ğŸ‘Ÿ **Shoes:** Consider **Donating** or dispose in the **GENERAL** bin.")
Â  Â  Â  Â  
Â  Â  Â  Â  st.markdown("### â¬› **General Waste**")
Â  Â  Â  Â  st.error("ğŸ—‘ï¸ **Trash:** Dispose in the **GENERAL** bin.")

# Main app logic
if st.session_state.is_detecting:
Â  Â  if st.session_state.is_webcam_active:
Â  Â  Â  Â  st.info("Detecting objects using webcam...")
Â  Â  Â  Â  
Â  Â  Â  Â  # Check if model is loaded before using WebRTC
Â  Â  Â  Â  if "yolo_model" in st.session_state:
Â  Â  Â  Â  Â  Â  webrtc_streamer(
Â  Â  Â  Â  Â  Â  Â  Â  key="yolo-stream",
Â  Â  Â  Â  Â  Â  Â  Â  # âœ… Pass the arguments using a lambda function
Â  Â  Â  Â  Â  Â  Â  Â  video_processor_factory=lambda: YOLOProcessor(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.yolo_model, 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.confidence_threshold
Â  Â  Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  Â  Â  rtc_configuration=ClientSettings(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rtc_offer_min_port=10000,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rtc_offer_max_port=10200,
Â  Â  Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  if "detected_classes" in st.session_state:
Â  Â  Â  Â  Â  Â  Â  Â  display_detection_messages(st.session_state.detected_classes)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error("YOLO model is not loaded. Please check the logs for errors.")
Â  Â  Â  Â  Â  Â  
Â  Â  elif uploaded_file:
Â  Â  Â  Â  file_extension = uploaded_file.name.split(".")[-1].lower()
Â  Â  Â  Â  if file_extension in ["jpg", "jpeg", "png"]:
Â  Â  Â  Â  Â  Â  st.info("Detecting objects in image...")
Â  Â  Â  Â  Â  Â  image_detection(uploaded_file, confidence_threshold, selected_classes)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("Video processing not implemented in this version")
else:
Â  Â  st.title("Smart Garbage Detection & Sorting Assistant")
Â  Â  st.info("Upload an image or video, or start the webcam for object detection.")
Â  Â  
Â  Â  col1, col2 = st.columns(2)
Â  Â  with col1:
Â  Â  Â  Â  st.write("""
Â  Â  Â  Â  ### ğŸ—‚ï¸ Garbage Detection Using YOLO
Â  Â  Â  Â  This is a group project by **Num Chakhatanon** and **Dawis Meedech** to help people sort garbage more easily.
Â  Â  Â  Â  
Â  Â  Â  Â  **Features:**
Â  Â  Â  Â  - Real-time object detection via webcam
Â  Â  Â  Â  - Image analysis
Â  Â  Â  Â  - Smart disposal recommendations
Â  Â  Â  Â  - Multiple waste categories supported
Â  Â  Â  Â  """)
Â  Â  
Â  Â  with col2:
Â  Â  Â  Â  st.write("""
Â  Â  Â  Â  ### ğŸ“– How to Use:
Â  Â  Â  Â  1. **Upload** an image or use your **webcam**
Â  Â  Â  Â  2. **Adjust** confidence threshold as needed
Â  Â  Â  Â  3. **Select** specific classes to detect (optional)
Â  Â  Â  Â  4. **Start detection** and follow the disposal instructions
Â  Â  Â  Â  
Â  Â  Â  Â  The system will automatically provide disposal guidance for detected items!
Â  Â  Â  Â  """)
```